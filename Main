{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive Crime Analysis and Prediction in São Paulo\n",
        "\n",
        "## Introduction\n",
        "The project aims to analyze crime data in São Paulo, identify trends and patterns, and develop predictive models to forecast future crime occurrences. The project will also explore the socio-economic factors influencing crime rates and provide actionable insights for policymakers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Collection and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Handle Missing Values and Inconsistencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/mnt/data/dataset-limpo.csv')\n",
        "\n",
        "# Checking for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "missing_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dropping rows with missing values in critical columns\n",
        "data_cleaned = data.dropna(subset=['bairro', 'descricao', 'registrou_bo'])\n",
        "\n",
        "# Filling missing values in 'ip_address_origin' with a placeholder\n",
        "data_cleaned['ip_address_origin'].fillna('unknown', inplace=True)\n",
        "\n",
        "# Verify the changes\n",
        "missing_values_cleaned = data_cleaned.isnull().sum()\n",
        "missing_values_cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Standardize Timestamps and Address Formats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Standardizing the timestamps\n",
        "data_cleaned['created_at'] = pd.to_datetime(data_cleaned['created_at'])\n",
        "data_cleaned['time'] = pd.to_datetime(data_cleaned['time'])\n",
        "\n",
        "# Removing duplicates\n",
        "data_cleaned = data_cleaned.drop_duplicates()\n",
        "\n",
        "# Verify the changes\n",
        "data_cleaned.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Summary statistics for numerical columns\n",
        "numerical_summary = data_cleaned.describe()\n",
        "\n",
        "# Summary statistics for categorical columns\n",
        "categorical_summary = data_cleaned.describe(include='object')\n",
        "\n",
        "numerical_summary, categorical_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.1 Temporal Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the number of incidents per year\n",
        "data_cleaned['year'] = data_cleaned['time'].dt.year\n",
        "incident_per_year = data_cleaned['year'].value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "incident_per_year.plot(kind='bar')\n",
        "plt.title('Number of Incidents per Year')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Incidents')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2 Spatial Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Number of incidents per neighborhood\n",
        "incident_per_bairro = data_cleaned['bairro'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "incident_per_bairro.head(20).plot(kind='bar')\n",
        "plt.title('Top 20 Neighborhoods by Number of Incidents')\n",
        "plt.xlabel('Neighborhood')\n",
        "plt.ylabel('Number of Incidents')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3 Category Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Distribution of crime types\n",
        "crime_types = data_cleaned['titulo'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "crime_types.plot(kind='bar')\n",
        "plt.title('Distribution of Crime Types')\n",
        "plt.xlabel('Crime Type')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predictive Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Objective\n",
        "Forecast the likelihood of being robbed and the value of items stolen in different neighborhoods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extracting features from timestamps\n",
        "data_cleaned['year'] = data_cleaned['time'].dt.year\n",
        "data_cleaned['month'] = data_cleaned['time'].dt.month\n",
        "data_cleaned['day'] = data_cleaned['time'].dt.day\n",
        "data_cleaned['hour'] = data_cleaned['time'].dt.hour\n",
        "\n",
        "# Encode categorical variables\n",
        "data_cleaned = pd.get_dummies(data_cleaned, columns=['bairro', 'titulo'], drop_first=True)\n",
        "\n",
        "# Prepare target variables\n",
        "data_cleaned['item_stolen'] = (data_cleaned[['Bicicleta', 'Bolsa ou Mochila', 'Carteira', 'Cartão de Crédito', \n",
        "                                             'Celular', 'Computador', 'DVD', 'Dinheiro', 'Documentos', \n",
        "                                             'Equipamento de Som', 'Estepe', 'MP4 ou Ipod', 'Móveis', \n",
        "                                             'Notebook', 'Outros', 'Relógio', 'Som', 'Tablet', 'Tv']].sum(axis=1) > 0).astype(int)\n",
        "data_cleaned['item_value'] = data_cleaned[['Bicicleta', 'Bolsa ou Mochila', 'Carteira', 'Cartão de Crédito', \n",
        "                                           'Celular', 'Computador', 'DVD', 'Dinheiro', 'Documentos', \n",
        "                                           'Equipamento de Som', 'Estepe', 'MP4 ou Ipod', 'Móveis', \n",
        "                                           'Notebook', 'Outros', 'Relógio', 'Som', 'Tablet', 'Tv']].sum(axis=1)\n",
        "\n",
        "# Save processed data for modeling\n",
        "data_cleaned.to_csv('/mnt/data/data_processed.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1 Predict Likelihood of Robbery"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load processed data\n",
        "data_processed = pd.read_csv('/mnt/data/data_processed.csv')\n",
        "\n",
        "# Features and target for likelihood prediction\n",
        "X = data_processed.drop(columns=['item_stolen', 'item_value', 'created_at', 'time', 'descricao', 'registrou_bo'])\n",
        "y = data_processed['item_stolen']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Classification Report:\\n{report}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.2 Predict Value of Items Stolen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Features and target for value prediction\n",
        "X = data_processed.drop(columns=['item_stolen', 'item_value', 'created_at', 'time', 'descricao', 'registrou_bo'])\n",
        "y = data_processed['item_value']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Socio-Economic Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: Correlation analysis with a socio-economic factor\n",
        "socio_economic_data = pd.read_csv('socio_economic_data.csv') # Load your socio-economic data\n",
        "\n",
        "# Merge with crime data\n",
        "data_merged = pd.merge(data_cleaned, socio_economic_data, on='neighborhood')\n",
        "\n",
        "# Correlation analysis\n",
        "correlation_matrix = data_merged.corr()\n",
        "print(correlation_matrix['crime_rate']) # Assuming 'crime_rate' is a column in your merged data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Impact Assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Assuming socio-economic factors are in columns ['income', 'unemployment_rate', 'education_level']\n",
        "X = data_merged[['income', 'unemployment_rate', 'education_level']]\n",
        "y = data_merged['crime_rate']\n",
        "\n",
        "# Add constant term for the regression model\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
